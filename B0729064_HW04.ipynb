{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"B0729064_HW04.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3.7.7 64-bit"},"language_info":{"name":"python","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"9164a3399a70d355c381b62813f30880ed90ca5a6f321bf0d85375640bda7ee5"}},"cells":[{"cell_type":"code","metadata":{"id":"JF5Fw8HnfEvQ"},"source":["/\n","/content/drive/MyDrive/NatureLanguageProgram/B0729064_NLP_HW4/wiki_zh/AB/wiki_00\n","/content/drive/MyDrive/NatureLanguageProgram/B0729064_NLP_HW4/wiki_zh/AA"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33gORW2la6Vc","executionInfo":{"status":"ok","timestamp":1629292876867,"user_tz":-480,"elapsed":41999,"user":{"displayName":"楊永川","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggx1XlzmI8P9pcajCEBcheu4kz3U9OvvaM8dTnb=s64","userId":"08079793556666005334"}},"outputId":"8a46ac43-629e-425f-dae8-d647aa78ceb8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ewA7BzMnkLMi"},"source":["import os\n","#path = \"/content/drive/MyDrive/NatureLanguageProgram/B0729064_NLP_HW4/wiki_zh/AA\" #資料夾目錄\n","#path = \"C:\\Users\\User\\OneDrive\\桌面\\同步到google雲端\\NatureLanguageProgram\\B0729064_NLP_HW4/wiki_zh/AA\" #資料夾目錄\n","#s = ['AA','AB','AC','AD','AE','AF','AG','AH','AI','AJ','AK','AL','AM']\n","s = ['AA','AB']\n","for i in s:\n","  path = \"/content/drive/MyDrive/NatureLanguageProgram/B0729064_NLP_HW4/wiki_zh/%s\"%(i)#資料夾目錄\n","  files= os.listdir(path) #得到資料夾下的所有檔名稱\n","  txt = []\n","  print(\"in \")\n","  print(i)\n","  print('\\n')\n","  for file in files: #遍歷資料夾\n","    if not os.path.isdir(file): #判斷是否是資料夾，不是資料夾才開啟\n","      f = open(path+\"/\"+ file); #開啟檔案\n","      iter_f = iter(f); #建立迭代器\n","      str = \"\"\n","      for line in iter_f: #遍歷檔案，一行行遍歷，讀取文字\n","        print(line)\n","        str = str + line\n","      txt.append(str) #每個檔案的文字存到list中\n","  print(txt) #列印結果\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZeIbeeAeuT1N"},"source":["import os\n","import json\n","#path = \"/content/drive/MyDrive/NatureLanguageProgram/B0729064_NLP_HW4/wiki_zh/AA\" #資料夾目錄\n","#path = \"C:\\Users\\User\\OneDrive\\桌面\\同步到google雲端\\NatureLanguageProgram\\B0729064_NLP_HW4/wiki_zh/AA\" #資料夾目錄\n","#s = ['AA','AB','AC','AD','AE','AF','AG','AH','AI','AJ','AK','AL','AM']\n","s = ['AA','AB']\n","for i in s:\n","  path = \"/content/drive/MyDrive/NatureLanguageProgram/B0729064_NLP_HW4/wiki_zh/%s\"%(i)#資料夾目錄\n","  files= os.listdir(path) #得到資料夾下的所有檔名稱\n","  txt = []\n","  for file in files: #遍歷資料夾\n","    if not os.path.isdir(file): #判斷是否是資料夾，不是資料夾才開啟\n","      file = open(path+\"/\"+ file, encoding='utf-8')\n","      for line in file.readlines():\n","        data = json.loads(line)\n","        print(data)\n","\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EbMbRSMeMTwm"},"source":["from gensim.models import word2vec\n","import jieba\n","from opencc import OpenCC\n","from gensim.models import word2vec, fasttext\n","import os\n","#s = ['AA','AB','AC','AD','AE','AF','AG','AH','AI','AJ','AK','AL','AM']\n","s = ['AA','AB']\n","for i in s:\n","  path = \"/content/drive/MyDrive/NatureLanguageProgram/B0729064_NLP_HW4/wiki_zh/%s\"%(i)#資料夾目錄\n","  files= os.listdir(path) #得到資料夾下的所有檔名稱\n","  s = []\n","  for file in files: #遍歷資料夾\n","    if not os.path.isdir(file): #判斷是否是資料夾，不是資料夾才開啟\n","      f = open(path+\"/\"+ file); #開啟檔案\n","      iter_f = iter(f); #建立迭代器\n","      str = \"\"\n","      for line in iter_f: #遍歷檔案，一行行遍歷，讀取文字\n","        print(line)\n","        str = str + line\n","      s.append(str) #每個檔案的文字存到list中\n","  print(s) #列印結果\n","\n","\n","\n","# Initial\n","cc = OpenCC('s2t')\n","\n","\n","# Tokenize\n","with open('wiki_text_seg.txt', 'w', encoding='utf-8') as new_f:\n","    with open('wiki_text.txt', 'r', encoding='utf-8') as f:\n","        for times, data in enumerate(f, 1):\n","            print('data num:', times)\n","            data = cc.convert(data)\n","            data = jieba.cut(data)\n","            data = [word for word in data if word != ' ']\n","            data = ' '.join(data)\n","\n","            new_f.write(data)\n","\n","# Settings\n","seed = 666\n","sg = 0\n","window_size = 10\n","vector_size = 100\n","min_count = 1\n","workers = 8\n","epochs = 5\n","batch_words = 10000\n","\n","train_data = word2vec.LineSentence('wiki_text_seg.txt')\n","model = word2vec.Word2Vec(\n","    train_data,\n","    min_count=min_count,\n","    vector_size=vector_size,\n","    workers=workers,\n","    epochs=epochs,\n","    window=window_size,\n","    sg=sg,\n","    seed=seed,\n","    batch_words=batch_words\n",")\n","\n","model.save('word2vec.model')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v7mE_Vt0MWCW"},"source":["from gensim.models import word2vec\n","\n","model = word2vec.Word2Vec.load('word2vec.model')\n","print(model.wv['生物'].shape)\n","\n","for item in model.wv.most_similar('生物'):\n","    print(item)"],"execution_count":null,"outputs":[]}]}